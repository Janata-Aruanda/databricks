{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "970c35fc-b8fe-4b70-8850-9dc66030ad75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n| id| nome|idade|\n+---+-----+-----+\n|  1| João|   25|\n|  2|Maria|   30|\n+---+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from delta.tables import *\n",
    "# Caminho para o diretório Delta Lake onde os dados serão armazenados\n",
    "delta_path = \"/path/evolutivo\"\n",
    "\n",
    "# Criação de um DataFrame de exemplo com um esquema inicial\n",
    "df = spark.createDataFrame([(1, \"João\", 25), (2, \"Maria\", 30)], [\"id\", \"nome\", \"idade\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d6c7d2-5656-4c29-87fe-95b2927195e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+---------------+---------------------------+---------+--------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n|version|timestamp          |userId         |userName                   |operation|operationParameters                   |job |notebook          |clusterId           |readVersion|isolationLevel   |isBlindAppend|operationMetrics                                           |userMetadata|engineInfo                         |\n+-------+-------------------+---------------+---------------------------+---------+--------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n|1      |2024-03-24 14:17:11|182265804626074|janataaruanda1999@gmail.com|WRITE    |{mode -> Overwrite, partitionBy -> []}|null|{1020864699828205}|0324-141316-eof15udn|0          |WriteSerializable|false        |{numFiles -> 2, numOutputRows -> 2, numOutputBytes -> 2775}|null        |Databricks-Runtime/12.2.x-scala2.12|\n|0      |2024-03-24 14:16:55|182265804626074|janataaruanda1999@gmail.com|WRITE    |{mode -> Overwrite, partitionBy -> []}|null|{1020864699828205}|0324-141316-eof15udn|null       |WriteSerializable|false        |{numFiles -> 2, numOutputRows -> 2, numOutputBytes -> 2185}|null        |Databricks-Runtime/12.2.x-scala2.12|\n+-------+-------------------+---------------+---------------------------+---------+--------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Salvando o DataFrame no formato Delta Lake\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
    "\n",
    "# Realizando uma atualização no esquema: adicionando uma nova coluna \"cidade\"\n",
    "df_novo_esquema = spark.createDataFrame([(1, \"João\", 25, \"São Paulo\"), (2, \"Maria\", 30, \"Rio de Janeiro\")],\n",
    "                                        [\"id\", \"nome\", \"idade\", \"cidade\"])\n",
    "\n",
    "# Salvando o DataFrame com o novo esquema no mesmo diretório Delta Lake\n",
    "df_novo_esquema.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(delta_path)\n",
    "\n",
    "# Carregando o DeltaTable a partir do caminho especificado\n",
    "delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "\n",
    "# Visualizando as versões disponíveis\n",
    "delta_table.history().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc3c340c-8afd-4e56-9f5d-982a9953cad6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+--------------+\n| id| nome|idade|        cidade|\n+---+-----+-----+--------------+\n|  2|Maria|   30|Rio de Janeiro|\n|  1| João|   25|     São Paulo|\n+---+-----+-----+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Lendo o DataFrame com o esquema evolutivo\n",
    "df_esquema_atual = spark.read.format(\"delta\").load(delta_path)\n",
    "# Exibindo o DataFrame resultante\n",
    "df_esquema_atual.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074f5136-ac0c-4d5b-a7f7-7c01d23edb88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n| id| nome|idade|\n+---+-----+-----+\n|  1| João|   25|\n|  2|Maria|   30|\n+---+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Carregando o DataFrame de uma versão anterior do Delta Lake\n",
    "df_versao_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_path)\n",
    "# Exibindo o DataFrame da versão 0\n",
    "df_versao_0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763d2af7-05c2-42f3-95d4-0799d4a63664",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.rm(\"/path/evolutivo\", recurse=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Deltalake3",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
